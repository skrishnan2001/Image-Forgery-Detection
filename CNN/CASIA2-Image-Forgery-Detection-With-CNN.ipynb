{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the libraries","metadata":{}},{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms.functional as tf\nimport pandas as pd\nimport os\nimport numpy as np\nfrom skimage.util import view_as_windows\nfrom skimage import io\nimport PIL\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport warnings\nimport cv2\nfrom skimage.metrics import structural_similarity\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-11-05T13:28:08.063814Z","iopub.execute_input":"2022-11-05T13:28:08.064119Z","iopub.status.idle":"2022-11-05T13:28:10.942055Z","shell.execute_reply.started":"2022-11-05T13:28:08.064096Z","shell.execute_reply":"2022-11-05T13:28:10.940230Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Patch Extraction Utility Functions","metadata":{}},{"cell_type":"code","source":"def check_and_reshape(image, input_mask):\n    \"\"\"\n    Gets an image reshapes it and returns it with its mask.\n    :param image: The image\n    :param input_mask: The mask of the image\n    :returns: the image and its mask\n    \"\"\"\n    try:\n        mask_x, mask_y = input_mask.shape\n        mask = np.empty((mask_x, mask_y, 3))\n        mask[:, :, 0] = input_mask\n        mask[:, :, 1] = input_mask\n        mask[:, :, 2] = input_mask\n    except ValueError:\n        mask = input_mask\n    if image.shape == mask.shape:\n        return image, mask\n    elif image.shape[0] == mask.shape[1] and image.shape[1] == mask.shape[0]:\n        mask = np.reshape(mask, (image.shape[0], image.shape[1], mask.shape[2]))\n        return image, mask\n    else:\n        return image,mask ","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.384439Z","iopub.execute_input":"2022-10-04T17:27:30.386195Z","iopub.status.idle":"2022-10-04T17:27:30.397829Z","shell.execute_reply.started":"2022-10-04T17:27:30.386128Z","shell.execute_reply":"2022-10-04T17:27:30.395900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_all_patches(image, window_shape, stride, num_of_patches, rotations, output_path, im_name, rep_num, mode):\n    \"\"\"\n    Extracts all the patches from an image.\n    :param image: The image\n    :param window_shape: The shape of the window (for example (128,128,3) in the CASIA2 dataset)\n    :param stride: The stride of the patch extraction\n    :param num_of_patches: The amount of patches to be extracted per image\n    :param rotations: The amount of rotations divided equally in 360 degrees\n    :param output_path: The output path where the patches will be saved\n    :param im_name: The name of the image\n    :param rep_num: The amount of repetitions\n    :param mode: If we account rotations 'rot' or nor 'no_rot'\n    \"\"\"\n    non_tampered_windows = view_as_windows(image, window_shape, step=stride)\n    non_tampered_patches = []\n    for m in range(non_tampered_windows.shape[0]):\n        for n in range(non_tampered_windows.shape[1]):\n            non_tampered_patches += [non_tampered_windows[m][n][0]]\n    # select random some patches, rotate and save them\n    save_patches(non_tampered_patches, num_of_patches, mode, rotations, output_path, im_name, rep_num,\n                 patch_type='authentic')","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.400035Z","iopub.execute_input":"2022-10-04T17:27:30.400594Z","iopub.status.idle":"2022-10-04T17:27:30.414086Z","shell.execute_reply.started":"2022-10-04T17:27:30.400543Z","shell.execute_reply":"2022-10-04T17:27:30.412817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def delete_prev_images(dir_name):\n    \"\"\"\n    Deletes all the file in a directory.\n    :param dir_name: Directory name\n    \"\"\"\n    for the_file in os.listdir(dir_name):\n        file_path = os.path.join(dir_name, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n        except Exception as e:\n            print(e)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.417810Z","iopub.execute_input":"2022-10-04T17:27:30.418361Z","iopub.status.idle":"2022-10-04T17:27:30.430809Z","shell.execute_reply.started":"2022-10-04T17:27:30.418307Z","shell.execute_reply":"2022-10-04T17:27:30.429558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dirs(output_path):\n    \"\"\"\n    Creates the directories to the output path.\n    :param output_path: The output path\n    \"\"\"\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n        os.makedirs(output_path + '/authentic')\n        os.makedirs(output_path + '/tampered')\n    else:\n        if os.path.exists(output_path + '/authentic'):\n            delete_prev_images(output_path + '/authentic')\n        else:\n            os.makedirs(output_path + '/authentic')\n        if os.path.exists(output_path + '/tampered'):\n            delete_prev_images(output_path + '/tampered')\n        else:\n            os.makedirs(output_path + '/tampered')","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.434657Z","iopub.execute_input":"2022-10-04T17:27:30.435981Z","iopub.status.idle":"2022-10-04T17:27:30.444577Z","shell.execute_reply.started":"2022-10-04T17:27:30.435910Z","shell.execute_reply":"2022-10-04T17:27:30.443027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_patches(patches, num_of_patches, mode, rotations, output_path, im_name, rep_num, patch_type):\n    \"\"\"\n    Saves all the extracted patches to the output path.\n    :param patches: The extracted patches\n    :param num_of_patches: The amount of patches to be extracted per image\n    :param mode: If we account rotations 'rot' or nor 'no_rot'\n    :param rotations: The amount of rotations divided equally in 360 degrees\n    :param output_path: The output path where the patches will be saved\n    :param im_name: The name of the image\n    :param rep_num: The amount of repetitions\n    :param patch_type: The mask of the image\n    \"\"\"\n    inds = np.random.choice(len(patches), num_of_patches, replace=False)\n    if mode == 'rot':\n        for i, ind in enumerate(inds):\n            image = patches[ind][0] if patch_type == 'tampered' else patches[ind]\n            for angle in rotations:\n                im_rt = tf.rotate(PIL.Image.fromarray(np.uint8(image)), angle=angle,\n                                  resample=PIL.Image.BILINEAR)\n                im_rt.save(output_path + '/{0}/{1}_{2}_{3}_{4}.png'.format(patch_type, im_name, i, angle, rep_num))\n    else:\n        for i, ind in enumerate(inds):\n            image = patches[ind][0] if patch_type == 'tampered' else patches[ind]\n            io.imsave(output_path + '/{0}/{1}_{2}_{3}.png'.format(patch_type, im_name, i, rep_num), image)","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.446251Z","iopub.execute_input":"2022-10-04T17:27:30.446891Z","iopub.status.idle":"2022-10-04T17:27:30.461998Z","shell.execute_reply.started":"2022-10-04T17:27:30.446850Z","shell.execute_reply":"2022-10-04T17:27:30.460364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_tampered_patches(image, im_name, mask, window_shape, stride, dataset, patches_per_image):\n    \"\"\"\n    Gets an image reshapes it and returns it with its mask.\n    :param image: The image\n    :param im_name: The name of the image\n    :param mask: The mask of the image\n    :param window_shape: The shape of the window (for example (128,128,3) in the CASIA2 dataset)\n    :param stride: The stride of the patch extraction\n    :param dataset: The name of the dataset\n    :param patches_per_image: The amount of patches to be extracted per image\n    :returns: the tampered patches and their amount\n    \"\"\"\n    # extract patches from images and masks\n    patches = view_as_windows(image, window_shape, step=stride)\n\n    if dataset == 'casia2':\n        mask_patches = view_as_windows(mask, window_shape, step=stride)\n    elif dataset == 'nc16':\n        mask_patches = view_as_windows(mask, (128, 128), step=stride)\n    else:\n        raise NotSupportedDataset('The datasets supported are casia2 and nc16')\n\n    tampered_patches = []\n    # find tampered patches\n    for m in range(patches.shape[0]):\n        for n in range(patches.shape[1]):\n            im = patches[m][n][0]\n            ma = mask_patches[m][n][0]\n            num_zeros = (ma == 0).sum()\n            num_ones = (ma == 255).sum()\n            total = num_ones + num_zeros\n            if dataset == 'casia2':\n                if num_zeros <= 0.99 * total:\n                    tampered_patches += [(im, ma)]\n            elif dataset == 'nc16':\n                if 0.80 * total >= num_ones >= 0.20 * total:\n                    tampered_patches += [(im, ma)]\n\n    # if patches are less than the given number then take the minimum possible\n    num_of_patches = patches_per_image\n    if len(tampered_patches) < num_of_patches:\n        print(\"Number of tampered patches for image {} is only {}\".format(im_name, len(tampered_patches)))\n        num_of_patches = len(tampered_patches)\n\n    return tampered_patches, num_of_patches","metadata":{"execution":{"iopub.status.busy":"2022-10-04T17:27:30.464456Z","iopub.execute_input":"2022-10-04T17:27:30.464884Z","iopub.status.idle":"2022-10-04T17:27:30.479780Z","shell.execute_reply.started":"2022-10-04T17:27:30.464845Z","shell.execute_reply":"2022-10-04T17:27:30.478499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Patch Extractor Class for CASIA 2 Dataset","metadata":{}},{"cell_type":"code","source":"class PatchExtractorCASIA:\n    \"\"\"\n    Patch extraction class\n    \"\"\"\n\n    def __init__(self, input_path, output_path, patches_per_image=4, rotations=8, stride=8, mode='no_rot'):\n        \"\"\"\n        Initialize class\n        :param patches_per_image: Number of samples to extract for each image\n        :param rotations: Number of rotations to perform\n        :param stride: Stride size to be used\n        \"\"\"\n        self.patches_per_image = patches_per_image\n        self.stride = stride\n        rots = [0, 90, 180, 270]\n        self.rotations = rots[:rotations]\n        self.mode = mode\n        self.input_path = input_path\n        self.output_path = output_path\n\n        # define the indices of the image names and read the authentic images\n        self.background_index = [13, 21]\n        au_index = [3, 6, 7, 12]\n        au_pic_list = glob(self.input_path + os.sep + 'Au' + os.sep + '*')\n        self.au_pic_dict = {\n            au_pic.split(os.sep)[-1][au_index[0]:au_index[1]] + au_pic.split(os.sep)[-1][au_index[2]:au_index[3]]:\n                au_pic for au_pic\n            in au_pic_list}\n\n    def extract_authentic_patches(self, sp_pic, num_of_patches, rep_num):\n        \"\"\"\n        Extracts and saves the patches from the authentic image\n        :param sp_pic: Name of tampered image\n        :param num_of_patches: Number of patches to be extracted\n        :param rep_num: Number of repetitions being done(just for the patch name)\n        \"\"\"\n        sp_name = sp_pic.split('/')[-1][self.background_index[0]:self.background_index[1]]\n        if sp_name in self.au_pic_dict.keys():\n            au_name = self.au_pic_dict[sp_name].split(os.sep)[-1].split('.')[0]\n            # define window size\n            window_shape = (128, 128, 3)\n            au_pic = self.au_pic_dict[sp_name]\n            au_image = plt.imread(au_pic)\n            # extract all patches\n            extract_all_patches(au_image, window_shape, self.stride, num_of_patches, self.rotations, self.output_path,\n                                au_name, rep_num, self.mode)\n\n    def extract_patches(self):\n        \"\"\"\n        Main function which extracts all patches\n        :return:\n        \"\"\"\n        # uncomment to extract masks\n#         mask_path = 'masks'\n#         if os.path.exists(mask_path) and os.path.isdir(mask_path):\n#             if not os.listdir(mask_path):\n#                 print(\"Extracting masks\")\n#                 extract_masks()\n#                 print(\"Masks extracted\")\n#             else:\n#                 print(\"Masks exist. Patch extraction begins...\")\n#         else:\n#             os.makedirs(mask_path)\n#             print(\"Extracting masks\")\n#             extract_masks()\n#             print(\"Masks extracted\")\n#         #\n\n        # create necessary directories\n        create_dirs(self.output_path)\n\n        # define window shape\n        window_shape = (128, 128, 3)\n        tp_dir = self.input_path+'/Tp/'\n        rep_num = 0\n        # run for all the tampered images\n        for f in os.listdir(tp_dir):\n            try:\n                if f == 'Thumbs.db' or f == '_list.txt':\n                    continue\n                rep_num += 1\n                image = io.imread(tp_dir + f)\n                im_name = f.split(os.sep)[-1].split('.')[0]\n                # read mask\n                mask = io.imread(self.input_path + '/CASIA 2 Groundtruth/' + im_name + '_gt.png')\n               \n                image, mask = check_and_reshape(image, mask)\n\n                # extract patches from images and masks\n                tampered_patches, num_of_patches = find_tampered_patches(image, im_name, mask,\n                                                                         window_shape, self.stride, 'casia2',\n                                                                         self.patches_per_image)\n                save_patches(tampered_patches, num_of_patches, self.mode, self.rotations, self.output_path, im_name,\n                             rep_num, patch_type='tampered')\n                self.extract_authentic_patches(tp_dir + f, num_of_patches, rep_num)\n            except IOError as e:\n                rep_num -= 1\n                print(str(e))\n            except IndexError:\n                rep_num -= 1\n                print('Mask and image have not the same dimensions')","metadata":{"execution":{"iopub.status.busy":"2022-10-22T11:55:39.068249Z","iopub.execute_input":"2022-10-22T11:55:39.068679Z","iopub.status.idle":"2022-10-22T11:55:39.089496Z","shell.execute_reply.started":"2022-10-22T11:55:39.068632Z","shell.execute_reply":"2022-10-22T11:55:39.088344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Patch Extraction Driver Code (CASIA Dataset)","metadata":{}},{"cell_type":"code","source":"pe = PatchExtractorCASIA(input_path='../input/casia-20-image-tampering-detection-dataset/CASIA2', output_path='patches_casia_with_rot',\n                         patches_per_image=2, stride=128, rotations=4, mode='rot')\npe.extract_patches()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the CNN model","metadata":{}},{"cell_type":"markdown","source":"### Filters","metadata":{}},{"cell_type":"code","source":"from typing import Dict\n\nimport numpy as np\nfrom torch import Tensor, stack\n\n\ndef get_filters():\n    \"\"\"\n    Function that return the required high pass SRM filters for the first convolutional layer of our implementation\n    :return: A pytorch Tensor containing the 30x3x5x5 filter tensor with type\n    [number_of_filters, input_channels, height, width]\n    \"\"\"\n\n    filters: Dict[str, Tensor] = {}\n\n    # 1st Order\n    filters[\"1O1\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, -1, 1, 0], [0, 0, 0, 0, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"1O2\"] = Tensor(np.rot90(filters[\"1O1\"]).copy())\n    filters[\"1O3\"] = Tensor(np.rot90(filters[\"1O2\"]).copy())\n    filters[\"1O4\"] = Tensor(np.rot90(filters[\"1O3\"]).copy())\n    filters[\"1O5\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, -1, 0, 0], [0, 0, 0, 0, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"1O6\"] = Tensor(np.rot90(filters[\"1O5\"]).copy())\n    filters[\"1O7\"] = Tensor(np.rot90(filters[\"1O6\"]).copy())\n    filters[\"1O8\"] = Tensor(np.rot90(filters[\"1O7\"]).copy())\n    # 2nd Order\n    filters[\"2O1\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 1, -2, 1, 0], [0, 0, 0, 0, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"2O2\"] = Tensor(np.rot90(filters[\"2O1\"]).copy())\n    filters[\"2O3\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, -2, 0, 0], [0, 0, 0, 1, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"2O4\"] = Tensor(np.rot90(filters[\"2O3\"]).copy())\n    # 3rd Order\n    filters[\"3O1\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 1, -3, 1, 0], [0, 0, 0, 0, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"3O2\"] = Tensor(np.rot90(filters[\"3O1\"]).copy())\n    filters[\"3O3\"] = Tensor(np.rot90(filters[\"3O2\"]).copy())\n    filters[\"3O4\"] = Tensor(np.rot90(filters[\"3O3\"]).copy())\n    filters[\"3O5\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, 1, 0, 1, 0], [0, 0, -3, 0, 0], [0, 1, 0, 0, 0],\n                                      [0, 0, 0, 0, 0]]))\n    filters[\"3O6\"] = Tensor(np.rot90(filters[\"3O5\"]).copy())\n    filters[\"3O7\"] = Tensor(np.rot90(filters[\"3O6\"]).copy())\n    filters[\"3O8\"] = Tensor(np.rot90(filters[\"3O7\"]).copy())\n    # 3x3 SQUARE\n    filters[\"3x3S\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, -1, 2, -1, 0], [0, 2, -4, 2, 0], [0, -1, 2, -1, 0],\n                                       [0, 0, 0, 0, 0]]))\n    # 3x3 EDGE\n    filters[\"3x3E1\"] = Tensor(np.array([[0, 0, 0, 0, 0], [0, -1, 2, -1, 0], [0, 2, -4, 2, 0], [0, 0, 0, 0, 0],\n                                        [0, 0, 0, 0, 0]]))\n    filters[\"3x3E2\"] = Tensor(np.rot90(filters[\"3x3E1\"]).copy())\n    filters[\"3x3E3\"] = Tensor(np.rot90(filters[\"3x3E2\"]).copy())\n    filters[\"3x3E4\"] = Tensor(np.rot90(filters[\"3x3E3\"]).copy())\n    # 5X5 EDGE\n    filters[\"5x5E1\"] = Tensor(np.array([[-1, 2, -2, 2, -1], [2, -6, 8, -6, 2], [-2, 8, -12, 8, -2],\n                                        [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]))\n    filters[\"5x5E2\"] = Tensor(np.rot90(filters[\"5x5E1\"]).copy())\n    filters[\"5x5E3\"] = Tensor(np.rot90(filters[\"5x5E2\"]).copy())\n    filters[\"5x5E4\"] = Tensor(np.rot90(filters[\"5x5E3\"]).copy())\n    # 5x5 SQUARE\n    filters[\"5x5S\"] = Tensor(np.array([[-1, 2, -2, 2, -1], [2, -6, 8, -6, 2], [-2, 8, -12, 8, -2],\n                                       [2, -6, 8, -6, 2], [-1, 2, -2, 2, -1]]))\n\n    return vectorize_filters(filters)\n\n\ndef vectorize_filters(filters: dict):\n    \"\"\"\n    Function that takes as input the 30x5x5 different SRM high pass filters and creates the 30x3x5x5 tensor with the\n    following permutations 𝑾𝑗 = [𝑊3𝑘−2 𝑊3𝑘−1 𝑊3𝑘] where 𝑘 = ((𝑗 − 1) mod 10) + 1 and (𝑗 = 1, ⋅ ⋅ ⋅ , 30).\n    :arg filters: The 30 SRM high pass filters\n    :return: Returns the 30x3x5x5 filter tensor of the type [number_of_filters, input_channels, height, width]\n    \"\"\"\n    tensor_list = []\n\n    w = list(filters.values())\n\n    for i in range(1, 31):\n        tmp = []\n\n        k = ((i - 1) % 10) + 1\n\n        tmp.append(w[3 * k - 3])\n        tmp.append(w[3 * k - 2])\n        tmp.append(w[3 * k - 1])\n\n        tensor_list.append(stack(tmp))\n\n    return stack(tensor_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:20:38.964905Z","iopub.execute_input":"2022-11-06T05:20:38.965876Z","iopub.status.idle":"2022-11-06T05:20:39.005973Z","shell.execute_reply.started":"2022-11-06T05:20:38.965830Z","shell.execute_reply":"2022-11-06T05:20:39.004181Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### CNN Class","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as f\nimport torch.nn as nn\n\n\nclass CNN(nn.Module):\n    \"\"\"\n    The convolutional neural network (CNN) class\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialization of all the layers in the network.\n        \"\"\"\n        super(CNN, self).__init__()\n\n        self.conv0 = nn.Conv2d(3, 3, kernel_size=5, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv0.weight)\n\n        self.conv1 = nn.Conv2d(3, 30, kernel_size=5, stride=2, padding=0)\n        self.conv1.weight = nn.Parameter(get_filters())\n\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        self.conv2 = nn.Conv2d(30, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv2.weight)\n\n        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv3.weight)\n\n        self.conv4 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv4.weight)\n\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        self.conv5 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv5.weight)\n\n        self.conv6 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv6.weight)\n\n        self.conv7 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv7.weight)\n\n        self.conv8 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n        nn.init.xavier_uniform_(self.conv8.weight)\n\n        self.fc = nn.Linear(16 * 5 * 5, 2)\n\n        self.drop1 = nn.Dropout(p=0.5)  # used only for the NC dataset\n\n    def forward(self, x):\n        \"\"\"\n        The forward step of the network that consumes an image patch and either uses a fully connected layer in the\n        training phase with a softmax or just returns the feature map after the final convolutional layer.\n        :returns: Either the output of the softmax during training or the 400-D feature representation at testing\n        \"\"\"\n        x = f.relu(self.conv0(x))\n        x = f.relu(self.conv1(x))\n        lrn = nn.LocalResponseNorm(3)\n        x = lrn(x)\n        x = self.pool1(x)\n        x = f.relu(self.conv2(x))\n        x = f.relu(self.conv3(x))\n        x = f.relu(self.conv4(x))\n        x = f.relu(self.conv5(x))\n        x = lrn(x)\n        x = self.pool2(x)\n        x = f.relu(self.conv6(x))\n        x = f.relu(self.conv7(x))\n        x = f.relu(self.conv8(x))\n        x = x.view(-1, 16 * 5 * 5)\n\n        # In the training phase we also need the fully connected layer with softmax\n        if self.training:\n            # x = self.drop1(x) # used only for the NC dataset\n            x = f.relu(self.fc(x))\n            x = f.softmax(x, dim=1)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:20:25.510483Z","iopub.execute_input":"2022-11-06T05:20:25.510927Z","iopub.status.idle":"2022-11-06T05:20:25.531774Z","shell.execute_reply.started":"2022-11-06T05:20:25.510884Z","shell.execute_reply":"2022-11-06T05:20:25.530500Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Script to train the CNN model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.autograd import Variable\nimport time\nimport numpy as np\n\n\ndef create_loss_and_optimizer(net, learning_rate=0.01):\n    \"\"\"\n    Creates the loss function and optimizer of the network.\n    :param net: The network object\n    :param learning_rate: The initial learning rate\n    :returns: The loss function and the optimizer\n    \"\"\"\n    loss = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.99, weight_decay=5 * 1e-4)\n    return loss, optimizer\n\n\ndef train_net(net, train_set, n_epochs, learning_rate, batch_size):\n    \"\"\"\n    Training of the CNN\n    :param net: The CNN object\n    :param train_set: The training part of the dataset\n    :param n_epochs: The number of epochs of the experiment\n    :param learning_rate: The initial learning rate\n    :param batch_size: The batch size of the SGD\n    :returns: The epoch loss (vector) and the epoch accuracy (vector)\n    \"\"\"\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n    criterion, optimizer = create_loss_and_optimizer(net, learning_rate)\n    scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n    n_batches = len(train_loader)\n    epoch_loss = []\n    epoch_accuracy = []\n\n    for epoch in range(n_epochs):\n\n        total_running_loss = 0.0\n        print_every = n_batches // 5\n        training_start_time = time.time()\n        c = 0\n        total_predicted = []\n        total_labels = []\n\n        for i, (inputs, labels) in enumerate(train_loader):\n            # get the inputs\n            if torch.cuda.is_available():\n                inputs = Variable(inputs.cuda())\n                labels = Variable(labels.cuda().long())\n            else:\n                inputs = Variable(inputs)\n                labels = Variable(labels)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            _, predicted = torch.max(outputs.data, 1)\n\n            total_labels.extend(labels)\n            total_predicted.extend(predicted)\n\n            if (i + 1) % (print_every + 1) == 0:\n                total_running_loss += loss.item()\n                c += 1\n\n        epoch_predictions = (np.array(total_predicted) == np.array(total_labels)).sum().item()\n        print('---------- Epoch %d Loss: %.3f Accuracy: %.3f Time: %.3f----------' % (\n            epoch + 1, total_running_loss / c, epoch_predictions / len(total_predicted),\n            time.time() - training_start_time))\n        epoch_accuracy.append(epoch_predictions / len(total_predicted))\n        epoch_loss.append(total_running_loss / c)\n        scheduler.step()\n\n    print('Finished Training')\n\n    return epoch_loss, epoch_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:20:49.989217Z","iopub.execute_input":"2022-11-06T05:20:49.990120Z","iopub.status.idle":"2022-11-06T05:20:50.010703Z","shell.execute_reply.started":"2022-11-06T05:20:49.990050Z","shell.execute_reply":"2022-11-06T05:20:50.009575Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### train_net.py -> Driver code for training the CNN model","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\n\n\ntorch.manual_seed(0)\n\nDATA_DIR = \"patches_casia_with_rot\"  # the directory of the augmented patches\ntransform = transforms.Compose([transforms.ToTensor()])\n\ndata = datasets.ImageFolder(root=DATA_DIR, transform=transform)  # Fetch data\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nif str(device) == \"cuda:0\":\n    print(\"cuda enabled\")\n    cnn = CNN().cuda()\nelse:\n    print(\"no cuda\")\n    cnn = CNN()\n\nepoch_loss, epoch_accuracy = train_net(cnn, data, n_epochs=40, learning_rate=0.0001, batch_size=128)\n\npd.DataFrame(epoch_loss).to_csv('SRM_loss.csv')\npd.DataFrame(epoch_accuracy).to_csv('SRM_accuracy.csv')\n\ntorch.save(cnn.state_dict(), 'Cnn.pt')\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T12:15:25.287247Z","iopub.execute_input":"2022-10-22T12:15:25.287725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"### Feature Fusion","metadata":{}},{"cell_type":"code","source":"import math\n\nimport torch\nimport numpy as np\n\n\ndef get_yi(model, patch):\n    \"\"\"\n    Returns the patch's feature representation\n    :param model: The pre-trained CNN object\n    :param patch: The patch\n    :returns: The 400-D feature representation of the patch\n    \"\"\"\n    with torch.no_grad():\n        model.eval()\n        return model(patch)\n\n\nclass WrongOperationOption(Exception):\n    pass\n\n\ndef get_y_hat(y: np.ndarray, operation: str):\n    \"\"\"\n    Fuses the image's patches feature representation\n    :param y: The network object\n    :param operation: Either max or mean for the pooling operation\n    :returns: The final 400-D feature representation of the entire image\n    \"\"\"\n    if operation == \"max\":\n        return np.array(y).max(axis=0, initial=-math.inf)\n    elif operation == \"mean\":\n        return np.array(y).mean(axis=0)\n    else:\n        raise WrongOperationOption(\"The operation can be either mean or max\")\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:20:56.878830Z","iopub.execute_input":"2022-11-06T05:20:56.879306Z","iopub.status.idle":"2022-11-06T05:20:56.888037Z","shell.execute_reply.started":"2022-11-06T05:20:56.879267Z","shell.execute_reply":"2022-11-06T05:20:56.886690Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Feature Vector Generation","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torch.autograd import Variable\n\n\ndef create_feature_vectors(model, tampered_path, authentic_path, output_name):\n    \"\"\"\n    Writes the feature vectors of the CASIA2 dataset.\n    :param model: The pre-trained CNN object\n    :param tampered_path: The path of the tampered images of the CASIA2 dataset\n    :param authentic_path: The path of the authentic images of the CASIA2 dataset\n    :param output_name: The name of the output CSV that contains the feature vectors\n    \"\"\"\n    df = pd.DataFrame()\n    images = get_images_and_labels(tampered_path, authentic_path)\n    c = 1\n    for image_name in images.keys():  # images\n        print(\"Image: \", c)\n\n        image = images[image_name]['mat']\n#         if c >= 4966:\n#             print(image)\n            \n        label = images[image_name]['label']\n        if image is not None:\n            df = pd.concat([df, pd.concat([pd.DataFrame([image_name.split(os.sep)[-1], str(label)]),\n                                           pd.DataFrame(get_patch_yi(model, image))])], axis=1, sort=False)\n        c += 1\n\n    # save the feature vector to csv\n    final_df = df.T\n    final_df.columns = get_df_column_names()\n    final_df.to_csv(output_name, index=False)  # csv type [im_name][label][f1,f2,...,fK]\n\n\ndef create_feature_vectors_nc(model, input_path, output_name):\n    \"\"\"\n    Writes the feature vectors of the NC 2016 dataset.\n    :param model: The pre-trained CNN object\n    :param input_path: The path of the dataset\n    :param output_name: The name of the output CSV that contains the feature vectors\n    \"\"\"\n    df = pd.DataFrame()\n    images = get_images_and_labels_nc()\n    c = 1\n    for image_name, label in images.items():  # images\n\n        print(\"Image: \", c)\n#         if c >= 4966:\n#             print(image)\n        if image_name == 'Thumbs.db':\n            continue\n            \n        image = io.imread(input_path + image_name)\n        if image is not None:\n            df = pd.concat([df, pd.concat([pd.DataFrame([image_name, str(label)]),\n                                       pd.DataFrame(get_patch_yi(model, image))])], axis=1, sort=False)\n        c += 1\n\n    # save the feature vector to csv\n    final_df = df.T\n    final_df.columns = get_df_column_names()\n    final_df.to_csv(output_name, index=False)  # csv type [im_name][label][f1,f2,...,fK]\n\n\ndef get_patch_yi(model, image):\n    \"\"\"\n    Calculates the feature representation of an image.\n    :param model: The pre-trained CNN object\n    :param image: The image\n    :returns: The image's feature representation\n    \"\"\"\n    transform = transforms.Compose([transforms.ToTensor()])\n\n    y = []  # init Y\n\n    patches = get_patches(image, stride=1024)\n\n    for patch in patches:  # for every patch\n        img_tensor = transform(patch)\n        img_tensor.unsqueeze_(0)\n        img_variable = Variable(img_tensor.double())\n        yi = get_yi(model=model, patch=img_variable)\n        y.append(yi)  # append Yi to Y\n\n    y = np.vstack(tuple(y))\n\n    y_hat = get_y_hat(y=y, operation=\"mean\")  # create Y_hat with mean or max\n\n    return y_hat\n\n\ndef get_df_column_names():\n    \"\"\"\n    Rename the feature csv column names as [im_names][labels][f1,f2,...,fK].\n    :returns: The column names\n    \"\"\"\n    names = [\"image_names\", \"labels\"]\n    for i in range(400):\n        names.append(\"f\" + str(i + 1))\n    return names\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:20:58.794614Z","iopub.execute_input":"2022-11-06T05:20:58.795054Z","iopub.status.idle":"2022-11-06T05:20:59.091689Z","shell.execute_reply.started":"2022-11-06T05:20:58.795017Z","shell.execute_reply":"2022-11-06T05:20:59.090817Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### patch_extraction.py","metadata":{}},{"cell_type":"code","source":"import glob\nimport cv2\nfrom skimage.util import view_as_windows\n\n\ndef get_patches(image_mat, stride):\n    \"\"\"\n    Extract patches rom an image\n    :param image_mat: The image as a matrix\n    :param stride: The stride of the patch extraction process\n    :returns: The patches\n    \"\"\"\n    window_shape = (128, 128, 3)\n    #print(image_mat)\n    patches = []\n    \n    image_map_nparray = np.array(image_mat)\n    #print(len(image_mat), 'x', len(image_mat[0]), 'x', len(image_mat[0][0]))\n    image_map_nparray.reshape(len(image_mat), len(image_mat[0]), len(image_mat[0][0]))\n    windows = view_as_windows(image_map_nparray, window_shape, step=stride)\n    \n    for m in range(windows.shape[0]):\n        for n in range(windows.shape[1]):\n            patches += [windows[m][n][0]]\n    return patches\n\n\ndef get_images_and_labels(tampered_path, authentic_path):\n    \"\"\"\n    Get the images and their corresponding labels\n    :param tampered_path: The path containing the tampered images\n    :param authentic_path: The path containing the authentic images\n    :returns: Dictionary with images and labels\n    \"\"\"\n    tampered_dir = tampered_path\n    authentic_dir = authentic_path\n    images = {}\n    for im in glob.glob(authentic_dir):\n        images[im] = {}\n        images[im]['mat'] = cv2.imread(im)\n        images[im]['label'] = 0\n    for im in glob.glob(tampered_dir):\n        images[im] = {}\n        images[im]['mat'] = cv2.imread(im)\n        images[im]['label'] = 1\n    return images\n\n\ndef get_images_and_labels_nc():\n    \"\"\"\n    Get the images and their corresponding labels for the NC 2016 dataset\n    :returns: Dictionary with images and labels\n    \"\"\"\n    refs = get_ref_df()\n    images = {}\n    for _, data in refs.iterrows():\n        if data['ProbeFileName'] in images:\n            continue\n        im = data['ProbeFileName']\n        images[im] = 1 if data['IsTarget'] == 'Y' else 0\n    return images\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:21:02.605818Z","iopub.execute_input":"2022-11-06T05:21:02.606466Z","iopub.status.idle":"2022-11-06T05:21:02.635948Z","shell.execute_reply.started":"2022-11-06T05:21:02.606431Z","shell.execute_reply":"2022-11-06T05:21:02.634759Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Feature Extraction Driver Code","metadata":{}},{"cell_type":"code","source":"import torch\n\n\nwith torch.no_grad():\n    model = CNN()\n    model.load_state_dict(torch.load('../input/pretrained-cnn/CASIA2_WithRot_LR001_b128_nodrop.pt',\n                                     map_location=lambda storage, loc: storage))\n    model.eval()\n    model = model.double()\n\n    authentic_path = '../input/casia-20-image-tampering-detection-dataset/CASIA2/Au/*'\n    tampered_path = '../input/casia-20-image-tampering-detection-dataset/CASIA2/Tp/*'\n    output_filename = 'CASIA2_WithRot_LR001_b128_nodrop.csv'\n    create_feature_vectors(model, tampered_path, authentic_path, output_filename)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-24T07:20:26.406117Z","iopub.execute_input":"2022-10-24T07:20:26.406785Z","iopub.status.idle":"2022-10-24T08:11:23.226416Z","shell.execute_reply.started":"2022-10-24T07:20:26.406748Z","shell.execute_reply":"2022-10-24T08:11:23.225413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM Classification","metadata":{}},{"cell_type":"markdown","source":"### SVM.py","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sn\n\n\ndef optimize_hyperparams(x, y, params):\n    \"\"\"\n    Hyperparameter optimization of the SVM\n    :param x: The feature vectors\n    :param y: The labels\n    :param params: The grid of all the possible optimal hyperparameters\n    :returns: The optimal hyperparameters\n    \"\"\"\n    # Optimize hyper-parameters\n    model = svm.SVC(probability=True)\n    model_grid_search = GridSearchCV(model, params, cv=10, n_jobs=5)\n    model_grid_search.fit(x.values, y.values)\n    print(\"Optimal hyper-parameters: \", model_grid_search.best_params_)\n    print(\"Accuracy :\", model_grid_search.best_score_)\n    return model_grid_search.best_params_\n\n\ndef classify(x, y, opt_params):\n    \"\"\"\n    Classify a feature vector using SVM and print some metrics\n    :param x: The feature vectors\n    :param y: The labels\n    :param opt_params: The optimal hyperparameters\n    \"\"\"\n    # Single SVM run with optimized hyperparameters and\n    model = svm.SVC(kernel='rbf', gamma=opt_params['gamma'], C=opt_params['C'], probability=True)\n    scores = cross_val_score(model, x, y, cv=10, scoring='accuracy', n_jobs=-1)\n    print(scores)\n    print(np.mean(scores))\n    print(np.std(scores))\n\n\ndef print_confusion_matrix(x, y, opt_params):\n    \"\"\"\n    Print the confusion matrix of an SVM classification\n    :param x: The feature vectors\n    :param y: The labels\n    :param opt_params: The optimal hyperparameters\n    \"\"\"\n    y_pred, y_test = get_predictions(x, y, opt_params)\n    # Printing out false/true positives/negatives\n    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n    print('True negatives: ', tn, 'False positives: ', fp, 'False negatives: ', fn, 'True positives: ', tp)\n\n    # Using seaborn to create a confusion matrix table\n    data = {'y_Predicted': y_pred, 'y_Actual': y_test}\n    df = pd.DataFrame(data, columns=['y_Actual', 'y_Predicted'])\n    conf_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n    sn.heatmap(conf_matrix, cmap=ListedColormap(['#ED7D31', '#009FDA']), annot=True, fmt='g', cbar=False)\n\n\ndef find_misclassified(x, y, opt_params, img_ids):\n    \"\"\"\n    Gets the misclassified image ids and writes them to a csv\n    :param x: The feature vectors\n    :param y: The labels\n    :param opt_params: The optimal hyperparameters\n    :param img_ids: The image ids that correspond to the feature vector(x)\n    \"\"\"\n    y_pred, y_test = get_predictions(x, y, opt_params)\n    misclassified = []\n    for i in range(len(y_test)):\n        if y_pred[i] != y_test.values[i]:\n            misclassified.append(str(y_pred[i]) + ',' + str(y_test.values[i]) + ',' + str(img_ids[y_test.index[i]]))\n    df = pd.DataFrame(misclassified)\n    df.columns = ['Prediction,Actual,ImageName']\n    df.to_csv('Misclassified.csv', index=False)\n\n\ndef get_predictions(x, y, opt_params):\n    \"\"\"\n    Classification using SVM\n    :param x: The feature vectors\n    :param y: The labels\n    :param opt_params: The optimal hyperparameters\n    :returns: The predicted and true labels\n    \"\"\"\n    # Run one SVM with 80-20 split\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n    model = svm.SVC(kernel='rbf', gamma=opt_params['gamma'], C=opt_params['C'], probability=True)\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n\n    return y_pred, y_test\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T03:38:21.365566Z","iopub.execute_input":"2022-11-06T03:38:21.366178Z","iopub.status.idle":"2022-11-06T03:38:21.384491Z","shell.execute_reply.started":"2022-11-06T03:38:21.366143Z","shell.execute_reply":"2022-11-06T03:38:21.383515Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### svm_classification.py (Driver for SVM Classifier)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Read features and labels from CSV\ndf = pd.read_csv(filepath_or_buffer='./CASIA2_WithRot_LR001_b128_nodrop.csv')\nX = df.loc[:, ~df.columns.isin(['labels', 'image_names'])]\ny = df['labels']\n\nimg_ids = df['image_names']\n\nprint('Has NaN:', df.isnull().values.any())\n\nhyper_params = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n\nopt_params = optimize_hyperparams(X, y, params=hyper_params)\nclassify(X, y, opt_params)\nprint_confusion_matrix(X, y, opt_params)\nfind_misclassified(X, y, opt_params, img_ids)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T03:38:21.386707Z","iopub.execute_input":"2022-11-06T03:38:21.387072Z","iopub.status.idle":"2022-11-06T05:19:52.405026Z","shell.execute_reply.started":"2022-11-06T03:38:21.387042Z","shell.execute_reply":"2022-11-06T05:19:52.403428Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Has NaN: False\nOptimal hyper-parameters:  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\nAccuracy : 0.9269073044686944\n[0.92234548 0.92472266 0.92709984 0.92472266 0.92466297 0.92942109\n 0.93180016 0.92862807 0.92942109 0.92624901]\n0.9269073044686944\n0.002745948978858654\nTrue negatives:  1397 False positives:  101 False negatives:  70 True positives:  955\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Training Accuracy and Training Loss Graph","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n\ndef plot_epochs(metric1, ylab, metric2=None):\n    \"\"\"\n    Plot the metrics of both datasets\n    :param metric1: The first metric that we want to plot\n    :param metric2: The second metric that we want to plot\n    :param ylab: The label of the y axis\n    \"\"\"\n    plt.plot(metric1, label='CASIA2')\n#     plt.plot(metric2, label='NC16')\n    plt.ylabel(ylab)\n    plt.xlabel(\"Epoch\")\n    plt.legend(loc='lower right')\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    df1 = pd.read_csv(filepath_or_buffer=\"../input/accuracy-loss/CASIA2_WithRot_LR001_b128_nodrop_Accuracy.csv\")\n#     df2 = pd.read_csv(filepath_or_buffer=\"../../data/output/accuracy/NC16_WithRot_LR001_b128_withdrop_Accuracy.csv\")\n    df3 = pd.read_csv(filepath_or_buffer=\"../input/accuracy-loss/CASIA2_WithRot_LR001_b128_nodrop_Loss.csv\")\n#     df4 = pd.read_csv(filepath_or_buffer=\"../../data/output/loss_function/NC16_WithRot_LR001_b128_withdrop_Loss.csv\")\n#     plot_epochs(df1.iloc[:, 1], df2.iloc[:, 1], 'Training Accuracy')\n    plot_epochs(df1.iloc[:, 1], 'Training Accuracy')\n#     plot_epochs(df3.iloc[:, 1], df4.iloc[:, 1], 'Training Loss')\n    plot_epochs(df3.iloc[:, 1], 'Training Loss')\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T05:19:52.407122Z","iopub.execute_input":"2022-11-06T05:19:52.407501Z","iopub.status.idle":"2022-11-06T05:19:52.872522Z","shell.execute_reply.started":"2022-11-06T05:19:52.407456Z","shell.execute_reply":"2022-11-06T05:19:52.871355Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Testing a sample Image","metadata":{}},{"cell_type":"code","source":"from joblib import load\nimport torch\nfrom cv2 import imread\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndef get_feature_vector(image_path: str, model):\n    feature_vector = np.empty((1, 400))\n    feature_vector[0, :] = get_patch_yi(model, imread(image_path))\n    return feature_vector\n\n\n# Load the pretrained CNN with the CASIA2 dataset\nwith torch.no_grad():\n    our_cnn = CNN()\n    our_cnn.load_state_dict(torch.load('../input/pretrained-cnn/CASIA2_WithRot_LR001_b128_nodrop.pt',\n                                       map_location=lambda storage, loc: storage))\n    our_cnn.eval()\n    our_cnn = our_cnn.double()\n\n# Load the pretrained svm model\nsvm_model = load('../input/pretrained-svm/CASIA2_WithRot_LR001_b128_nodrop.pt')\n\nprint(\"Labels are 0 for non-tampered and 1 for tampered\")\n\n# Probe the SVM model with a non-tampered image\nnon_tampered_image_path = '../input/testimages/Au_ani_00002.jpg'\nnon_tampered_image_feature_vector = get_feature_vector(non_tampered_image_path, our_cnn)\n#print(\"Non tampered image feature vector: \", non_tampered_image_feature_vector)\nprediction_svm = svm_model.predict(non_tampered_image_feature_vector)\nprint(\"Non tampered prediction:\", prediction_svm)\n# print(\"Confidence: \", svm_model.predict_proba())\n# Probe the SVM model with a tampered image\ntampered_image_path = '../input/testimages/Tp_D_CNN_M_B_nat00056_nat00099_11105.jpg'\ntampered_image_feature_vector = get_feature_vector(tampered_image_path, our_cnn)\n#print(\"Tampered image feature vector: \", tampered_image_feature_vector)\nprediction_svm = svm_model.predict(tampered_image_feature_vector)\nprint(\"Tampered prediction: \", prediction_svm)\n# print(\"Confidence: \", predict_proba())\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T06:31:20.314719Z","iopub.execute_input":"2022-11-06T06:31:20.316144Z","iopub.status.idle":"2022-11-06T06:31:20.382921Z","shell.execute_reply.started":"2022-11-06T06:31:20.316077Z","shell.execute_reply":"2022-11-06T06:31:20.380779Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Labels are 0 for non-tampered and 1 for tampered\nNon tampered prediction: [0]\nTampered prediction:  [1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CASIA Test Dataset (50 Authentic and 50 Tampered Images)","metadata":{}},{"cell_type":"code","source":"import os\nfrom os import listdir\n \n# get the path or directory\ntest_folder_dir = \"../input/casiatestdataset\"\n\nprint(\"CASIA Test dataset: 50 authentic & 50 tampered images\")\nprint(\"Labels are 0 for non-tampered and 1 for tampered\")\n\ncount_not_tampered, count_tampered = 0, 0\n\nfor images in os.listdir(test_folder_dir):\n \n    # check if the image ends with png or jpg or jpeg\n    if (images.endswith(\".png\") or images.endswith(\".jpg\")\\\n        or images.endswith(\".jpeg\") or images.endswith(\".tif\")):\n        test_image_path = test_folder_dir + '/' + images\n        test_image_feature_vector = get_feature_vector(test_image_path, our_cnn)\n        #print(\"Tampered image feature vector: \", tampered_image_feature_vector)\n        prediction_svm = svm_model.predict(test_image_feature_vector)\n        print(\"Image name: \", images) \n        print(\"Tampered prediction: \", prediction_svm[0])\n        if(prediction_svm[0] == 1):\n            count_tampered += 1\n        else:\n            count_not_tampered += 1\n\nprint(\"No of authentic images: \", count_not_tampered)\nprint(\"No of tampered images: \", count_tampered)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-11-06T06:54:17.349394Z","iopub.execute_input":"2022-11-06T06:54:17.349853Z","iopub.status.idle":"2022-11-06T06:54:18.953623Z","shell.execute_reply.started":"2022-11-06T06:54:17.349812Z","shell.execute_reply":"2022-11-06T06:54:18.952499Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"CASIA Test dataset: 50 authentic & 50 tampered images\nLabels are 0 for non-tampered and 1 for tampered\nImage name:  Au_sec_30319.jpg\nTampered prediction:  1\nImage name:  Au_sec_30296.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat00059_ani00070_11414.jpg\nTampered prediction:  1\nImage name:  Au_sec_30323.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat00097_ani00017_11412.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_nat10156_ani00024_12016.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00059_ani00005_11415.jpg\nTampered prediction:  1\nImage name:  Au_sec_30287.jpg\nTampered prediction:  0\nImage name:  Au_sec_30294.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10139_ani00058_11951.jpg\nTampered prediction:  1\nImage name:  Au_sec_30321.jpg\nTampered prediction:  0\nImage name:  Au_sec_30295.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_ind00091_ind00091_10647.jpg\nTampered prediction:  1\nImage name:  Au_sec_30303.jpg\nTampered prediction:  0\nImage name:  Au_sec_30284.jpg\nTampered prediction:  0\nImage name:  Au_sec_30278.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10109_pla00020_11355.jpg\nTampered prediction:  1\nImage name:  Au_sec_30309.jpg\nTampered prediction:  0\nImage name:  Au_sec_30289.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_nat00089_nat00062_10577.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_nat10139_nat00095_11947.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00063_art00025_11437.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00063_nat00061_11436.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10131_ani00005_11903.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00098_cha00072_11462.jpg\nTampered prediction:  1\nImage name:  Au_sec_30317.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10138_arc10125_11941.jpg\nTampered prediction:  1\nImage name:  Au_sec_30302.jpg\nTampered prediction:  0\nImage name:  Au_sec_30316.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_nat00089_nat00089_10576.jpg\nTampered prediction:  1\nImage name:  Au_sec_30325.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10125_ani00070_11634.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10123_ani00017_11411.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10126_ani10123_11651.jpg\nTampered prediction:  1\nImage name:  Au_sec_30313.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10120_cha00063_11389.jpg\nTampered prediction:  1\nImage name:  Au_sec_30301.jpg\nTampered prediction:  0\nImage name:  Au_sec_30298.jpg\nTampered prediction:  0\nImage name:  Au_sec_30282.jpg\nTampered prediction:  0\nImage name:  Au_sec_30322.jpg\nTampered prediction:  0\nImage name:  Au_sec_30286.jpg\nTampered prediction:  0\nImage name:  Au_sec_30310.jpg\nTampered prediction:  0\nImage name:  Au_sec_30306.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_sec10110_sec10101_10298.tif\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00099_ani00078_10527.tif\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00076_nat00086_10081.tif\nTampered prediction:  1\nImage name:  Au_sec_30308.jpg\nTampered prediction:  0\nImage name:  Au_sec_30320.jpg\nTampered prediction:  0\nImage name:  Au_sec_30288.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10139_ani00005_11950.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10125_ani00017_11636.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10125_ani00005_11635.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00044_ani00005_11435.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_ind00091_ind00091_10648.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10115_cha00052_11477.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10139_cha00070_11943.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10131_ani00070_11902.jpg\nTampered prediction:  1\nImage name:  Au_sec_30304.jpg\nTampered prediction:  0\nImage name:  Au_sec_30327.jpg\nTampered prediction:  0\nImage name:  Au_sec_30312.jpg\nTampered prediction:  0\nImage name:  Au_sec_30280.jpg\nTampered prediction:  0\nImage name:  Au_sec_30318.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10109_pla00050_11356.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_nat00090_nat00090_10575.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_nat00013_cha00042_11093.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10139_cha00063_11942.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10123_ani00070_11417.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_txt00049_txt00050_10374.tif\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00041_nat00041_00655.tif\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat00098_ani00058_11461.jpg\nTampered prediction:  1\nImage name:  Au_sec_30293.jpg\nTampered prediction:  0\nImage name:  Au_sec_30283.jpg\nTampered prediction:  0\nImage name:  Au_sec_30326.jpg\nTampered prediction:  0\nImage name:  Au_sec_30311.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat00062_ani00058_11418.jpg\nTampered prediction:  1\nImage name:  Au_sec_30290.jpg\nTampered prediction:  0\nImage name:  Au_sec_30285.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10109_pla00049_11357.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10139_ani00070_11944.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_sec00011_cha00085_11227.jpg\nTampered prediction:  1\nImage name:  Au_sec_30279.jpg\nTampered prediction:  0\nImage name:  Au_sec_30307.jpg\nTampered prediction:  0\nImage name:  Au_sec_30324.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_sec10107_sec10101_10299.tif\nTampered prediction:  1\nImage name:  Au_sec_30314.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10106_nat10107_11349.jpg\nTampered prediction:  1\nImage name:  Au_sec_30291.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_pla00042_pla00042_10976.jpg\nTampered prediction:  1\nImage name:  Au_sec_30315.jpg\nTampered prediction:  0\nImage name:  Au_sec_30292.jpg\nTampered prediction:  0\nImage name:  Au_sec_30281.jpg\nTampered prediction:  0\nImage name:  Tp_D_NRN_S_N_nat10116_cha00086_11371.jpg\nTampered prediction:  1\nImage name:  Tp_D_CNN_M_N_nat00077_nat00077_10574.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10123_ani00005_11419.jpg\nTampered prediction:  1\nImage name:  Au_sec_30299.jpg\nTampered prediction:  0\nImage name:  Au_sec_30305.jpg\nTampered prediction:  0\nImage name:  Au_sec_30300.jpg\nTampered prediction:  0\nImage name:  Au_sec_30297.jpg\nTampered prediction:  0\nImage name:  Tp_D_CNN_M_N_nat00041_nat10123_11439.jpg\nTampered prediction:  1\nImage name:  Tp_D_NRN_S_N_nat10117_nat10124_11344.jpg\nTampered prediction:  1\nNo of authentic images:  49\nNo of tampered images:  51\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Labels in the wild dataset test (201 Tampered Images)","metadata":{}},{"cell_type":"code","source":"import os\nfrom os import listdir\n \n# get the path or directory\ntest_folder_dir = \"../input/labels-in-the-wild/images\"\n\nprint(\"Labels in the wild dataset: 201 Tampered Images\")\nprint(\"Labels are 0 for non-tampered and 1 for tampered\")\n\ncount_not_tampered, count_tampered = 0, 0\n\nfor images in os.listdir(test_folder_dir):\n \n    # check if the image ends with png or jpg or jpeg\n    if (images.endswith(\".png\") or images.endswith(\".jpg\")\\\n        or images.endswith(\".jpeg\") or images.endswith(\".tif\")):\n        test_image_path = test_folder_dir + '/' + images\n        test_image_feature_vector = get_feature_vector(test_image_path, our_cnn)\n        #print(\"Tampered image feature vector: \", tampered_image_feature_vector)\n        prediction_svm = svm_model.predict(test_image_feature_vector)\n        print(\"Image name: \", images) \n        print(\"Tampered prediction: \", prediction_svm[0])\n        if(prediction_svm[0] == 1):\n            count_tampered += 1\n        else:\n            count_not_tampered += 1\n\nprint(\"No of authentic images: \", count_not_tampered)\nprint(\"No of tampered images: \", count_tampered)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-11-06T06:52:49.967318Z","iopub.execute_input":"2022-11-06T06:52:49.968721Z","iopub.status.idle":"2022-11-06T06:53:01.878141Z","shell.execute_reply.started":"2022-11-06T06:52:49.968656Z","shell.execute_reply":"2022-11-06T06:53:01.876892Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Labels in the wild dataset: 201 Tampered Images\nLabels are 0 for non-tampered and 1 for tampered\nImage name:  im23_edit5.jpg\nTampered prediction:  1\nImage name:  im36_edit3.jpg\nTampered prediction:  0\nImage name:  im21_edit1.jpg\nTampered prediction:  1\nImage name:  im13_edit1.jpg\nTampered prediction:  0\nImage name:  5482.jpg\nTampered prediction:  0\nImage name:  im9_edit2.jpg\nTampered prediction:  0\nImage name:  im31_edit3.jpg\nTampered prediction:  0\nImage name:  im9_edit4.jpg\nTampered prediction:  1\nImage name:  2844.jpg\nTampered prediction:  0\nImage name:  5789.jpg\nTampered prediction:  0\nImage name:  5266.jpg\nTampered prediction:  0\nImage name:  im41_edit2.jpg\nTampered prediction:  0\nImage name:  im27_edit2.jpg\nTampered prediction:  1\nImage name:  im4_edit1.jpg\nTampered prediction:  0\nImage name:  im35_edit4.jpg\nTampered prediction:  0\nImage name:  5483.jpg\nTampered prediction:  0\nImage name:  im37_edit1.jpg\nTampered prediction:  1\nImage name:  im32_edit4.jpg\nTampered prediction:  0\nImage name:  im24_edit3.jpg\nTampered prediction:  0\nImage name:  im2_edit3.jpg\nTampered prediction:  1\nImage name:  im31_edit13.jpg\nTampered prediction:  0\nImage name:  im19_edit1.jpg\nTampered prediction:  0\nImage name:  5656.jpg\nTampered prediction:  0\nImage name:  5200.jpg\nTampered prediction:  0\nImage name:  2564.jpg\nTampered prediction:  0\nImage name:  2874.jpg\nTampered prediction:  0\nImage name:  im3_edit1.jpg\nTampered prediction:  0\nImage name:  im30_edit3.jpg\nTampered prediction:  0\nImage name:  im34_edit1.jpg\nTampered prediction:  0\nImage name:  5118.jpg\nTampered prediction:  0\nImage name:  im37_edit2.jpg\nTampered prediction:  0\nImage name:  5693.jpg\nTampered prediction:  0\nImage name:  im14_edit1.jpg\nTampered prediction:  0\nImage name:  im24_edit2.jpg\nTampered prediction:  0\nImage name:  5808.jpg\nTampered prediction:  0\nImage name:  im30_edit1.jpg\nTampered prediction:  0\nImage name:  im32_edit3.jpg\nTampered prediction:  0\nImage name:  im31_edit11.jpg\nTampered prediction:  0\nImage name:  5698.jpg\nTampered prediction:  0\nImage name:  im22_edit1.jpg\nTampered prediction:  0\nImage name:  im22_edit2.jpg\nTampered prediction:  0\nImage name:  im7_edit2.jpg\nTampered prediction:  0\nImage name:  5270.jpg\nTampered prediction:  0\nImage name:  5567.jpg\nTampered prediction:  0\nImage name:  2810.jpg\nTampered prediction:  0\nImage name:  im42_edit5.jpg\nTampered prediction:  0\nImage name:  im32_edit2.jpg\nTampered prediction:  0\nImage name:  im35_edit3.jpg\nTampered prediction:  0\nImage name:  im24_edit1.jpg\nTampered prediction:  1\nImage name:  im18_edit2.jpg\nTampered prediction:  1\nImage name:  5264.jpg\nTampered prediction:  0\nImage name:  2896.jpg\nTampered prediction:  0\nImage name:  im36_edit4.jpg\nTampered prediction:  0\nImage name:  im33_edit2.jpg\nTampered prediction:  0\nImage name:  im8_edit1.jpg\nTampered prediction:  0\nImage name:  im37_edit7.jpg\nTampered prediction:  0\nImage name:  im38_edit1.jpg\nTampered prediction:  1\nImage name:  im17_edit2.jpg\nTampered prediction:  0\nImage name:  2705.jpg\nTampered prediction:  0\nImage name:  im23_edit1.jpg\nTampered prediction:  0\nImage name:  2308.jpg\nTampered prediction:  0\nImage name:  im36_edit2.jpg\nTampered prediction:  0\nImage name:  im35_edit1.jpg\nTampered prediction:  1\nImage name:  im32_edit1.jpg\nTampered prediction:  0\nImage name:  im31_edit7.jpg\nTampered prediction:  0\nImage name:  im35_edit9.jpg\nTampered prediction:  1\nImage name:  im25_edit4.jpg\nTampered prediction:  1\nImage name:  im30_edit6.jpg\nTampered prediction:  1\nImage name:  im11_edit1.jpg\nTampered prediction:  0\nImage name:  im9_edit3.jpg\nTampered prediction:  0\nImage name:  2318.jpg\nTampered prediction:  0\nImage name:  5836.jpg\nTampered prediction:  0\nImage name:  im41_edit1.jpg\nTampered prediction:  1\nImage name:  2574.jpg\nTampered prediction:  0\nImage name:  im23_edit4.jpg\nTampered prediction:  0\nImage name:  im30_edit5.jpg\nTampered prediction:  1\nImage name:  im35_edit2.jpg\nTampered prediction:  0\nImage name:  im37_edit6.jpg\nTampered prediction:  0\nImage name:  im35_edit8.jpg\nTampered prediction:  0\nImage name:  2839.jpg\nTampered prediction:  0\nImage name:  im31_edit2.jpg\nTampered prediction:  0\nImage name:  im35_edit12.jpg\nTampered prediction:  0\nImage name:  im7_edit4.jpg\nTampered prediction:  1\nImage name:  im31_edit1.jpg\nTampered prediction:  0\nImage name:  5544.jpg\nTampered prediction:  0\nImage name:  5537.jpg\nTampered prediction:  0\nImage name:  5304.jpg\nTampered prediction:  0\nImage name:  2395.jpg\nTampered prediction:  0\nImage name:  2915.jpg\nTampered prediction:  0\nImage name:  im19_edit3.jpg\nTampered prediction:  0\nImage name:  5559.jpg\nTampered prediction:  0\nImage name:  5179.jpg\nTampered prediction:  0\nImage name:  im35_edit7.jpg\nTampered prediction:  1\nImage name:  im37_edit4.jpg\nTampered prediction:  1\nImage name:  im16_edit1.jpg\nTampered prediction:  0\nImage name:  im32_edit8.jpg\nTampered prediction:  0\nImage name:  im2_edit2.jpg\nTampered prediction:  0\nImage name:  im9_edit1.jpg\nTampered prediction:  1\nImage name:  5204.jpg\nTampered prediction:  0\nImage name:  5481.jpg\nTampered prediction:  0\nImage name:  5558.jpg\nTampered prediction:  0\nImage name:  5137.jpg\nTampered prediction:  0\nImage name:  im7_edit6.jpg\nTampered prediction:  1\nImage name:  im31_edit8.jpg\nTampered prediction:  0\nImage name:  im36_edit1.jpg\nTampered prediction:  1\nImage name:  im37_edit5.jpg\nTampered prediction:  1\nImage name:  im37_edit3.jpg\nTampered prediction:  1\nImage name:  im11_edit2.jpg\nTampered prediction:  1\nImage name:  5781.jpg\nTampered prediction:  0\nImage name:  im29_edit2.jpg\nTampered prediction:  0\nImage name:  im1_edit1.jpg\nTampered prediction:  1\nImage name:  2251.jpg\nTampered prediction:  0\nImage name:  5707.jpg\nTampered prediction:  0\nImage name:  5731.jpg\nTampered prediction:  0\nImage name:  2511.jpg\nTampered prediction:  0\nImage name:  im25_edit1.jpg\nTampered prediction:  0\nImage name:  im33_edit1.jpg\nTampered prediction:  0\nImage name:  5801.jpg\nTampered prediction:  0\nImage name:  5435.jpg\nTampered prediction:  0\nImage name:  im1_edit4.jpg\nTampered prediction:  0\nImage name:  im42_edit1.jpg\nTampered prediction:  0\nImage name:  im41_edit3.jpg\nTampered prediction:  0\nImage name:  im35_edit11.jpg\nTampered prediction:  1\nImage name:  im20_edit1.jpg\nTampered prediction:  0\nImage name:  im27_edit1.jpg\nTampered prediction:  0\nImage name:  im7_edit7.jpg\nTampered prediction:  0\nImage name:  im32_edit6.jpg\nTampered prediction:  0\nImage name:  2908.jpg\nTampered prediction:  0\nImage name:  im12_edit2.jpg\nTampered prediction:  0\nImage name:  im14_edit2.jpg\nTampered prediction:  0\nImage name:  5813.jpg\nTampered prediction:  0\nImage name:  2508.jpg\nTampered prediction:  0\nImage name:  5735.jpg\nTampered prediction:  0\nImage name:  im36_edit5.jpg\nTampered prediction:  0\nImage name:  2217.jpg\nTampered prediction:  0\nImage name:  im35_edit5.jpg\nTampered prediction:  1\nImage name:  im12_edit1.jpg\nTampered prediction:  1\nImage name:  5763.jpg\nTampered prediction:  0\nImage name:  2536.jpg\nTampered prediction:  0\nImage name:  im19_edit2.jpg\nTampered prediction:  1\nImage name:  im39_edit1.jpg\nTampered prediction:  0\nImage name:  im31_edit9.jpg\nTampered prediction:  0\nImage name:  5660.jpg\nTampered prediction:  0\nImage name:  im17_edit1.jpg\nTampered prediction:  1\nImage name:  im31_edit6.jpg\nTampered prediction:  0\nImage name:  im30_edit4.jpg\nTampered prediction:  0\nImage name:  im30_edit2.jpg\nTampered prediction:  1\nImage name:  im8_edit4.jpg\nTampered prediction:  0\nImage name:  2785.jpg\nTampered prediction:  0\nImage name:  im42_edit2.jpg\nTampered prediction:  0\nImage name:  im1_edit2.jpg\nTampered prediction:  0\nImage name:  im32_edit5.jpg\nTampered prediction:  1\nImage name:  2701.jpg\nTampered prediction:  0\nImage name:  im35_edit6.jpg\nTampered prediction:  0\nImage name:  im1_edit3.jpg\nTampered prediction:  0\nImage name:  im2_edit1.jpg\nTampered prediction:  0\nImage name:  5839.jpg\nTampered prediction:  0\nImage name:  5046.jpg\nTampered prediction:  0\nImage name:  im26_edit1.jpg\nTampered prediction:  1\nImage name:  2882.jpg\nTampered prediction:  0\nImage name:  im7_edit3.jpg\nTampered prediction:  0\nImage name:  5193.jpg\nTampered prediction:  0\nImage name:  im25_edit5.jpg\nTampered prediction:  0\nImage name:  5821.jpg\nTampered prediction:  0\nImage name:  im15_edit2.jpg\nTampered prediction:  1\nImage name:  2581.jpg\nTampered prediction:  0\nImage name:  im40_edit1.jpg\nTampered prediction:  0\nImage name:  5492.jpg\nTampered prediction:  0\nImage name:  im42_edit4.jpg\nTampered prediction:  0\nImage name:  5367.jpg\nTampered prediction:  0\nImage name:  5811.jpg\nTampered prediction:  0\nImage name:  im6_edit1.jpg\nTampered prediction:  1\nImage name:  5198.jpg\nTampered prediction:  0\nImage name:  5143.jpg\nTampered prediction:  0\nImage name:  im32_edit9.jpg\nTampered prediction:  0\nImage name:  5770.jpg\nTampered prediction:  0\nImage name:  im19_edit4.jpg\nTampered prediction:  0\nImage name:  5834.jpg\nTampered prediction:  0\nImage name:  2577.jpg\nTampered prediction:  0\nImage name:  im32_edit7.jpg\nTampered prediction:  0\nImage name:  2525.jpg\nTampered prediction:  0\nImage name:  im31_edit12.jpg\nTampered prediction:  0\nImage name:  5609.jpg\nTampered prediction:  0\nImage name:  2301.jpg\nTampered prediction:  0\nImage name:  im5_edit1.jpg\nTampered prediction:  0\nImage name:  im12_edit3.jpg\nTampered prediction:  0\nImage name:  im25_edit3.jpg\nTampered prediction:  1\nImage name:  im31_edit5.jpg\nTampered prediction:  0\nImage name:  im23_edit2.jpg\nTampered prediction:  1\nImage name:  5055.jpg\nTampered prediction:  0\nImage name:  im37_edit8.jpg\nTampered prediction:  0\nImage name:  im18_edit1.jpg\nTampered prediction:  0\nImage name:  5696.jpg\nTampered prediction:  0\nImage name:  5708.jpg\nTampered prediction:  0\nImage name:  im25_edit2.jpg\nTampered prediction:  1\nImage name:  im8_edit3.jpg\nTampered prediction:  1\nImage name:  2867.jpg\nTampered prediction:  0\nImage name:  im23_edit3.jpg\nTampered prediction:  0\nImage name:  im28_edit1.jpg\nTampered prediction:  0\nImage name:  im42_edit3.jpg\nTampered prediction:  0\nImage name:  im31_edit4.jpg\nTampered prediction:  0\nNo of authentic images:  162\nNo of tampered images:  39\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Conclusion: \n\nThe CNN approach is seen to be very efficient with the CASIA dataset, where the iamge tampering were not very challenging (Splicing in specific). The CNN's accuracy for the CASIA dataset is 92.69 %. \n\nHowever, when we tested with 'Labels in the Wild' data set where the image tampering were much more challenging, the CNN model could only identify 39 out of the 201 tampered images. Thus the accuracy for this dataset is very less - 19.41%! So we need a better approach that can identify much more complex tampering in images.","metadata":{}}]}